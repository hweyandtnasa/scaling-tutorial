\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{color}
\usepackage{hyperref}

\lstset{language=Python}
\definecolor{mygray}{rgb}{0.9,0.9,0.9}

\title{A Primer on Scaling for Multi-Disciplinary Optimization in OpenMDAO and Dymos}
\author{Harvey Weyandt}
\date{}

\begin{document}

\maketitle

\tableofcontents

\newpage
\section{Scaling Fundamentals}

\addcontentsline{toc}{subsection}{What scaling is and why we do it}
\subsection*{What scaling is and why we do it}

A typical issue plaguing most treatments of the topic of scaling is a vagueness of terms, so to begin our treatment of scaling here we will clarify some terminology.

\textbf{Problem scaling}---or simply \textbf{scaling}, when understood to be with respect to a problem---is the act of transforming one optimization problem into another by applying transformations to its variables and rewriting the problem in terms of the transformed variables. Note that the variables can be inputs or outputs. 

The problem transformation applied in the act of problem scaling is called a \textbf{problem scaling transformation}. The individual transformations applied to the problem variables during scaling are called \textbf{variable scaling transformations}, and the act of applying those is called \textbf{variable scaling}---or just \textbf{scaling}, when understood to be with respect to variables, not an entire problem. Scaling transformations of problems and variables can simply be called \textbf{scaling transformations} when the context is clear. The inverses of scaling transformations, when they are available, are called \textbf{descaling transformations}, and applying such transformations to a scaled problem or its variables is called \textbf{descaling}.

In the context of scaling one problem $P$ into a new problem $\hat{P}$, the original problem $P$ is called the \textbf{unscaled problem} while the new problem $\hat{P}$ is called the \textbf{scaled problem}. The variables of these problems are then dubbed ``unscaled'' (a.k.a. ``physical'') and ``scaled'', respectively.
\\

\noindent
Suppose we wanted to numerically solve a problem $P$ with some solution method implementation \texttt{M} that is given initial guess information $P_{guess}^*$. The convergence behavior we would observe while \texttt{M} runs is determined in part by the formulation of $P$. For example, if some problem variables are evaluated in units that are too large or too small relative to those of other variables, then operations between these variables may incur significant error in the numerical results, to such a degree that convergence is either egregiously slow, egregiously inaccurate, or impossible altogether. 

The convergence issues in the above example may be circumvented by an informed (or lucky) choice of \texttt{M} and $P_{guess}^*$, but not always. Thus the best course of action in this case, if \texttt{M} and $P_{guess}^*$ are not to be questioned, is to reformulate $P$ in terms of new units, in such a way that the errors occurring in the execution of \texttt{M} are minimal and consequently the convergence behavior of \texttt{M} is optimal. Since changing the units of a variable amounts to applying a transformation to that variable, and problem scaling is precisely the application of transformations like these to the problem variables, this is another way of saying that the best course of action is to scale $P$ into a new problem $\hat{P}$ (particularly via changes in units). After applying the scaling transformation, $\hat{P}$ can then be solved to yield some optimum $\hat{x}^*$, which can be descaled to an optimum $x^*$ of $P$ by converting back to the old units.

Therein lies the utility of scaling, in general. If we choose our scaling transformation just right, we can transform a ``poorly-scaled'' problem $P$, conducive of poor convergence, into a ``well-scaled'' problem $\hat{P}$, conducive of more desirable convergence (with respect to a given solution method implementation and some given initial guess information). The scaled solution to $\hat{P}$ can then be descaled to, hopefully, yield a close approximation to the unscaled solution of $P$.
\\

\noindent
In summary, scaling provides an \textit{indirect} method for solving optimization problems. The method consists of the following three steps:
\begin{enumerate}
    \item \textit{Scale} problem $P$ into problem $\hat{P}$
    \item \textit{Solve} $\hat{P}$ directly for scaled optimum $\hat{x}^*$
    \item \textit{Descale} $\hat{x}^*$ to approximate unscaled optimum $x^*$
\end{enumerate}

\noindent
The nice thing is that OpenMDAO does all of this automatically! All you need to do is tell it what scaling transformation to apply. This you do by specifying units, if desired, and setting reference values. (See Section ?? for details.)

\addcontentsline{toc}{subsection}{The common scaling transformations}
\subsection*{The common scaling transformations}

Recall that a problem scaling transformation $S$ transforms a problem $P$ into a new problem $\hat{P}$:
\begin{align*}
    S(P) = \hat{P}
\end{align*}
It does this by applying a set of variable scaling transformations to the variables of $P$. For each variable $v$ of $P$, the problem scaling transformation $S$ provides a variable scaling transformation $S_v$ to transform it into scaled variable $\hat{v}$ of $\hat{P}$:
\begin{align*}
    S_v(v) = \hat{v}
\end{align*}
If a variable $v$ is untouched by $S$, then $S_v$ is simply the identity transformation, so that $\hat{v} = S_v(v) = v$. \\

\noindent
While scaling transformations are defined above in a very general sense, specific types of transformations are most commonly used. The most significant and commonplace types are ``linear'' and ``affine'', as described below. \\

\noindent \textit{Linear Scaling} \\

\noindent
$S$ is called \textbf{linear} if the variable transformations it defines are all linear maps---that is, if
\begin{align*}
    \hat{v} = S_v(v) = \alpha_v v
\end{align*}
for all $v$, where $\alpha_v$ is constant. \\

\noindent
The majority of unit changes encountered in scientific work are linear scaling transformations. For example, if our problem had a scalar state variable $x$ expressed in meters (m), then in units of millimeters (mm) it is $10^3x$, so the change from m to mm corresponds to a linear scaling transformation
\begin{align*}
    \hat{x} = S_x(x) = 10^3x
\end{align*}


\noindent \textit{Affine Scaling} \\

\noindent
Generalizing linear scaling to include possible ``shifts'' in variables leads to the notion of affine scaling. $S$ is called \textbf{affine} (pronounced ``ay-fine'') if the variable transformations it defines are all affine maps---that is, if
\begin{align*}
    \hat{v} = S_v(v) = \alpha_v v + \beta_v
\end{align*}
for all $v$, where $\alpha_v$,$\beta_v$ are constant. Note that if all $\beta_v = 0$, that means that $S$ is linear. All linear transformations are affine, but not all affine transformations are linear. \\

\noindent
Some unit conversions require affine transformations. For instance, converting a variable $T$ measured in degrees Celsius ($^{\circ}$C) to a new variable $\hat{T}$ measured in degrees Fahrenheit ($^{\circ}$F) requires the affine scaling transformation
\begin{align*}
    \hat{T} = S_T(T) = \frac{9}{5}T + 32
\end{align*}

\noindent
More will be said about linear and affine scaling later, since those are the types of transformations that the OpenMDAO user interface currently supports. (See Section ?? for details.)

\addcontentsline{toc}{subsection}{Rules of thumb and words of warning}
\subsection*{Rules of thumb and words of warning}

How do you know when a problem is poorly-scaled? How do you know that scaling the
problem can yield sufficiently significant convergence benefits? And how do you know what scaling transformations to use to reap those benefits? These are all very difficult, nuanced questions to answer precisely, and various aspects of these questions are still open areas of study, but nonetheless a few rules of thumb have been observed to work well in most instances.

Firstly, a problem may be poorly-scaled if at least one of its variables is allowed to take on values spanning several orders of magnitude. A distance measure that can assume significant values $0.01 \text{m}$ and $10000 \text{m}$, for example, spans at least six orders of magnitude and is likely to cause poor scaling in a problem. Outliers can have the same effect, stretching the precision with which a variable must be measured, thus causing it to span greater orders of magnitude, leading to poor scaling.

Secondly, a problem may be poorly-scaled if its variables can take on values that span several orders of magnitude \textit{relative to each other}. This phenomenon has the potential to disturb gradient-based methods because the optimization may consequently be too sensitive to changes in some variables while not being sensitive enough to changes in others. Imagine the contour graph of an objective function. If one variable is of, say, a far greater order of magnitude than the others, then the contours will be excessively "stretched" along that variable's coordinate axis, eliminating much of the curvature necessary for good convergence behavior under gradient-based methods.

Usually it helps to scale problem variables to be less disparate with respect to themselves and each other, as described above. The conventional way to do this is to "normalize" each variable so that its scaled value lies within $[0,1]$ or $[-1,1]$. Ross et al (2018) warn, however, that this is not an end-all-be-all solution to poor scaling, because normalizing the \textit{primal variables} in this way may have adverse effects on the scales of the \textit{dual variables}, consequently disturbing the "balancing" of the problem with regards to the necessary conditions for optimality generated by Pontryagin's principle. Still, it is often worth trying.

\newpage
\section{Scaling in OpenMDAO}

The OpenMDAO user interface provides support for linear and affine scaling, both \textit{indirectly} by allowing users to specify units for variables of interest, and \textit{directly} via either \texttt{scaler}/\texttt{adder} or \texttt{ref}/\texttt{ref0} keyword argument assignments. \\

\noindent
\textbf{Warning:} As of OpenMDAO V2, the \texttt{scaler}/\texttt{adder} interface for direct scaling is deprecated, so use \texttt{ref}/\texttt{ref0} instead! The following discussions of \texttt{scaler} and \texttt{adder} are only made to explain how to interpret the older programs that use them.

\addcontentsline{toc}{subsection}{Scalers and adders (deprecated)}
\subsection*{Scalers and adders (deprecated)}

To scale a variable this way, you must specify a \texttt{scaler} and an \texttt{adder}. How do these values translate to an affine scaling transformation? Well, if $x$ is the unscaled variable, then its scaled counterpart $\hat{x}$ is given by
\begin{align}
    \hat{x} = \texttt{scaler} \cdot (x + \texttt{adder}) \label{eq:scaler_adder_trans}
\end{align}
This means that, in terms of an affine transformation, \texttt{scaler} is the constant multiplier and $\texttt{scaler} \cdot \texttt{adder}$ is the constant shift term. \\

\addcontentsline{toc}{subsection}{Reference values}
\subsection*{Reference values}

The preferred way to directly scale variables is through \textit{reference values}. Most variables defined in OpenMDAO are associated with at least two types of reference values: \texttt{ref} and \texttt{ref0}. \\

\noindent
The \texttt{ref} value for a variable is defined to be the value that scales to 1, and the \texttt{ref0} value is that which scales to 0. Symbolically,
\begin{align*}
    \texttt{ref} &\mapsto 1 \\
    \texttt{ref0} &\mapsto 0
\end{align*}
Hence the scaling transformation from the corresponding variable $x$ to $\hat{x}$ is precisely
\begin{align}
    \hat{x} = \frac{x - \texttt{ref0}}{\texttt{ref} - \texttt{ref0}} \label{eq:ref_scale}
\end{align}
This means that, in terms of an affine transformation, the constant multiplier is $\frac{1}{\texttt{ref} - \texttt{ref0}}$ and the constant shift term is $-\frac{\texttt{ref0}}{\texttt{ref} - \texttt{ref0}}$. \\

\noindent
Note that, given variable $x$, if $x^U$ denotes an upper bound of $x$ and $x^L$ denotes a lower bound of $x$, then the domain interval $[x^L,x^U]$ is transformed as follows:
\begin{align*}
    [x^L,x^U] &\mapsto [\hat{x}^L,\hat{x}^U] \\
    &= \Big[\frac{x^L-\texttt{ref0}}{\texttt{ref}-\texttt{ref0}},\frac{x^U-\texttt{ref0}}{\texttt{ref}-\texttt{ref0}}\Big] \\
\end{align*}
\\ \\
\noindent
\textbf{Problem:} Find \texttt{ref},\texttt{ref0} such that the resulting scaling transformation maps the physical domain interval $[a,b]$ to the interval $[\hat{a},\hat{b}]$. \\

\noindent
\textbf{Solution:} Equation~\eqref{eq:ref_scale} gives $\hat{a},\hat{b}$ in terms of $a,b,\texttt{ref},\texttt{ref0}$, and solving the resulting linear system for \texttt{ref},\texttt{ref0} yields
\begin{align*}
    \texttt{ref} &= \frac{1-\hat{b}}{\hat{a}-\hat{b}}a + \frac{\hat{a}-1}{\hat{a}-\hat{b}}b \\
    \texttt{ref0} &= -\frac{\hat{b}}{\hat{a}-\hat{b}}a + \frac{\hat{a}}{\hat{a}-\hat{b}}b
\end{align*}
Note that \texttt{ref},\texttt{ref0} are simply linear combinations of the physical bounds whose coefficients are determined by the scaled bounds. \\
\\ \\
\noindent
\textbf{Problem:} Given \texttt{scaler} and \texttt{adder}, compute \texttt{ref} and \texttt{ref0}. \\

\noindent
\textbf{Solution:} Since \texttt{ref} is defined as the physical value that scales to 1, and \texttt{ref0} is defined as the physical value that scales to 0, Equation~\eqref{eq:scaler_adder_trans} gives equations that can be solved for \texttt{ref} and \texttt{ref0} to yield the following identities:
\begin{align*}
    \texttt{ref} &= \frac{1}{\texttt{scaler}} - \texttt{adder} \\
    \texttt{ref0} &= -\texttt{adder}
\end{align*}
If instead \texttt{scaler} and \texttt{adder} were desired from \texttt{ref} and \texttt{ref0}, the above equations would form a linear system that could be solved for those values to yield the following inverse identities:
\begin{align*}
    \texttt{scaler} &= \frac{1}{\texttt{ref} - \texttt{ref0}} \\
    \texttt{adder} &= -\texttt{ref0}
\end{align*}

\noindent
Note that values for \texttt{ref}/\texttt{ref0}, if they are set, override values for \texttt{scaler}/\texttt{adder} in OpenMDAO code, since the latter are deprecated.

\addcontentsline{toc}{subsection}{A Simple Example}
\subsection*{A Simple Example}

Suppose we wish to solve the following simple optimization problem in OpenMDAO:
\begin{equation*}
\begin{aligned}
& \text{minimize} & & f \equiv 10^6 x + 7 y \\
& \text{subject to} & & g \equiv 10^7 x + 8 y \leq 500 \\
& & & h \equiv 10^{12} x + 10^6 y \geq 50 \cdot 10^6
\end{aligned}
\end{equation*}
Listing~\ref{lst:simple_ex} shows an implementation of this problem in OpenMDAO. Note that Scipy's SLSQP is designated as the optimizer and our initial guess is $(x,y) = (0,1)$.

\begin{lstlisting}[caption=Simple Optimization Problem Example in OpenMDAO, frame=single, backgroundcolor=\color{mygray}, label={lst:simple_ex}]
import openmdao.api as om

prob = om.Problem()
model = prob.model

ivc = model.add_subsystem('ivc', om.IndepVarComp())
ivc.add_output('x')
ivc.add_output('y')

model.add_subsystem('obj', om.ExecComp('f = 1e6*x + 7*y'))
model.add_subsystem('con1', om.ExecComp('g = 1e7*x + 8*y'))
model.add_subsystem('con2', om.ExecComp('h = 1e12*x + 1e6*y'))

model.connect('ivc.x', ['obj.x', 'con1.x', 'con2.x'])
model.connect('ivc.y', ['obj.y', 'con1.y', 'con2.y'])

prob.driver = om.ScipyOptimizeDriver()
prob.driver.options['optimizer'] = 'SLSQP'

model.add_design_var('ivc.x')
model.add_design_var('ivc.y')
model.add_objective('obj.f')
model.add_constraint('con1.g', upper=500)
model.add_constraint('con2.h', lower=5e7)

prob.setup()

prob.set_val('ivc.x', 0)
prob.set_val('ivc.y', 1)

prob.run_driver()
\end{lstlisting}

Running this implementation as-is will not yield a solution, due to numerical difficulties. (To be sure, using a more powerful optimizer like pyOptSparse's SNOPT would overcome these difficulties in this case, but it won't always! So, for the purposes of illustrating scaling here, we will stick with SLSQP.) Luckily, the numerical difficulties can be overcome with effective problem scaling.

How do we know that scaling can help? It turns out that our example problem is poorly-scaled since convergence is generally hindered---if not outright precluded---by numerical difficulties that arise due to the vast disparity in relative orders of magnitude between the quantities $x,y,f,g,h$. The hint to this fact lies in the disparity between coefficients in the problem statement (some $10^6$s here, an $8$ here, a $10^{12}$ there...) For example, if we take $x=1$ and $y=1$, then $f$ is greater than $x,y$ by $6$ orders of magnitude, $g$ is greater than $x,y$ by $7$ orders of magnitude, and $h$ is greater than $x,y$ by a whole $12$ orders of magnitude. Recall that disparity in orders of magnitude is not always an indicator of poor scaling, but here it is because the scaling of the variables can be shown to lead to a very ill-conditioned jacobian matrix, which of course causes problems many of OpenMDAO's gradient-based solution methods.

How do we approach scaling this problem to make it more well-behaved? In other words, what problem variables should we scale, and how, to make this problem well-scaled? How, then, do we set the appropriate reference values for each variable? \\

Perhaps the best approach in this case is to scale $x$ to $\hat{x} = 10^6 x$ and $h$ to $\hat{h} = 10^{-6} h$, so that our problem becomes
\begin{equation*}
\begin{aligned}
& \text{minimize} & & f \equiv \hat{x} + 7 y \\
& \text{subject to} & & g \equiv 10 \hat{x} + 8 y \leq 500 \\
& & & \hat{h} \equiv \hat{x} + y \geq 50
\end{aligned}
\end{equation*}
Now our problem variables are all within three or four orders of magnitude of each other, thus making for a more well-conditioned jacobian which is much more conducive to well-behaved convergence.

Note that the idea in this example was essentially to scale variables to eliminate unwieldy coefficients. The fact that $x$ was amplified by at least an order of $6$ in each equation/inequality was a hint that $x$ is too "small" of a variable, needing to be "scaled up" at least to $\hat{x} = 10^6 x$; and the fact that both sides of the inequality constraint on $h$ could be reduced by an order of $6$ after that was a hint that $h$ is too "large", needing to be "scaled down" at least to $\hat{h} = 10^{-6} h$. \\

To apply our scaling scheme to the OpenMDAO implementation, we would need to set the \texttt{ref}/\texttt{ref0} values for $x$ and $h$. (Since $y,f,g$ are untouched, we do nothing to them.) What are these? \\

The \texttt{ref0} for each variable is, by definition, the value that scales to 0, which is obviously 0 for both $x$ and $h$. On the other hand, the \texttt{ref} for each variable is, by definition, the value that scales to 1; thus the \texttt{ref} for $x$ would be $10^{-6}$ and the \texttt{ref} for $h$ would be $10^6$. \\

To actually set the \texttt{ref}/\texttt{ref0} values in the code, we need to pass them in through the corresponding keyword arguments in \verb|add_design_var()| and \verb|add_constraint()|:

\begin{lstlisting}[frame=single, backgroundcolor=\color{mygray}]
model.add_design_var('ivc.x', ref=1e-6)
...
model.add_constraint('con2.h', lower=5e7, ref=1e6)
\end{lstlisting}
\noindent
Run the modified code and, \textit{voila}, the optimization converges without a hitch!

\addcontentsline{toc}{subsection}{Under the hood}
\subsection*{Under the hood}

See the \href{http://openmdao.org/twodocs/versions/latest/tags/Scaling.html}{Scaling} section of the OpenMDAO V2 documentation for more on scaling in OpenMDAO. For more in-depth information on how OpenMDAO handles scaling, visit the \href{http://openmdao.org/twodocs/versions/latest/theory_manual/scaling.html}{Scaling Variables in OpenMDAO} section.

\newpage
\section{Scaling in Dymos}

All of the advice from the previous section on OpenMDAO still applies, since Dymos is build on top of OpenMDAO. However, there are some particular facets to Dymos that are owed consideration.

\addcontentsline{toc}{subsection}{Defect constraint reference values}
\subsection*{Defect constraint reference values}

Dymos utilizes transcription methods, such as high-order Gauss-Lobatto and Radau pseudospectral methods, to convert dynamically-constrained optimal control problems (OCPs) into nonlinear programming (NLP) problems that are solvable within the OpenMDAO framework. The NLP problems generated by such transcription methods involve collocation defect constraints for each discretized input. These defect constraints can be scaled individually through the Dymos UI via \textit{defect constraint reference values}, or \texttt{defect\_ref} values.

[TODO: How to set defect refs]

\addcontentsline{toc}{subsection}{An example of defect scaling}
\subsection*{An example of defect scaling}

[TODO: Setting defect refs in X57 MPT Mod2 Power Phase]

\addcontentsline{toc}{subsection}{Under the hood}
\subsection*{Under the hood}

Refer to the \href{https://openmdao.github.io/dymos/index.html}{Dymos documentation} for more details on scaling in Dymos.

\newpage
\section{Selected Scaling Techniques}

[TODO: Preamble]

\addcontentsline{toc}{subsection}{Isoscaling}
\subsection*{Isoscaling}

\subsubsection*{Formulation}

The first and simplest of the methods described by Sagliano et al (2017) for scaling dynamically-constrained optimal control problems that are solved via transcription is the \textbf{isoscaling} (IS) method. In IS, the discretized states/controls $\textbf{V}$ and their corresponding collocation defect constraints $\textbf{F}$ are scaled according to
\begin{align*}
    \Hat{\textbf{V}} &= \text{K} \textbf{V} + \text{b} \\
    \Hat{\textbf{F}} &= \text{K}_\textbf{F} \textbf{F}
\end{align*}
where $\text{K}$ is a diagonal matrix whose diagonal elements are given by
\begin{align*}
    \text{ent}_{i,i} \text{K} &= \frac{1}{\textbf{V}_i^U - \textbf{V}_i^L} \\
\end{align*}
where $\textbf{V}_i^U, \textbf{V}_i^L$ are the upper and lower bounds of $\textbf{V}_i$, respectively; $\text{K}_\textbf{F}$ is the diagonal submatrix of $\text{K}$ formed by taking only the rows and columns corresponding to discretized \textit{states}, not controls; and $\text{b}$ is a vector whose elements are given by
\begin{align*}
    \text{b}_i &= \frac{\textbf{V}_i^L}{\textbf{V}_i^U - \textbf{V}_i^L}
\end{align*}

\noindent
To be perfectly explicit, the objects $\textbf{V},\Hat{\textbf{V}},\textbf{V}^U,\textbf{V}^L,\textbf{F},\Hat{\textbf{F}},\text{K},\text{K}_\textbf{F},\text{b}$ have the following dimensions:
\begin{align*}
    \text{dim} \textbf{V} = \text{dim} \Hat{\textbf{V}} = \text{dim} \textbf{V}^U = \text{dim} \textbf{V}^L = \text{dim}\,\text{b} &= N \times 1 \\
    \text{dim} \textbf{F} = \text{dim} \Hat{\textbf{F}} &= n_sn \times 1 \\
    \text{dim} \text{K} &= N \times N \\
    \text{dim} \text{K}_\textbf{F} &= n_sn \times n_sn
\end{align*}
where $N$ is the number of state variables in the \textit{discrete} NLP problem resulting from transcription, $n_s$ is the number of state variables in the \textit{continuous} optimal control problem, and $n$ is the number of discretization nodes utilized in the transcription.

\subsubsection*{Implementation}

How exactly do the equations defining IS translate into reference values that can be used in OpenMDAO/Dymos?

[Since $\textbf{F}$ is a matrix with $n_sn$ rows, we may choose to index rows not with a single integer index $i$, but rather with one string index $v$ and another integer index $\mu$, where $v$ specifies the name of a discretized variable and $\mu$ specifies the particular node of that variable's discretization. This choice enables a straightforward interpretation of the formulae in terms of \texttt{ref}s, \texttt{ref0}s, and \texttt{defect\_ref}s.]

The \texttt{defect\_ref} to be set for state $x$, for all discretization nodes, is given by
\begin{align*}
    \texttt{defect\_ref}_x &= x^U - x^L
\end{align*}
i.e. the range of $x$. (Recall that $x^U$,$x^L$ are to be chosen artificially if $x$ is unbounded.)

As for the states (and controls) themselves, \texttt{ref} and \texttt{ref0} for each state/control $v$ are given simply by the upper and lower bounds $v^U,v^L$, respectively:
\begin{align*}
    \texttt{ref}_v &= v^U \\
    \texttt{ref0}_v &= v^L
\end{align*}

\subsubsection*{Properties, pros and cons}

Note that the formulation of IS given above does not touch path constraints $\textbf{G}$. This is intentional, though Sagliano et al do not explain the rationale. Likely, the path constraints $\textbf{G}$---and, indeed, non-defect constraints in general---are not scaled by $\text{K}$ because such constraints do not depend upon the states/controls, in the way that the defect constraints do. For defect constraints, the constraint variable and the constraint itself are both dependent upon the state/control to which it pertains; whereas for non-defect constraints, the constraint variable is obviously going to be dependent on \textit{some} subset of the states/controls, while the constraint \textit{itself}---the equality or inequality statement relating the constraint variable to some fixed value(s)---are \textit{not} dependent on any such subset.

An obvious benefit to IS is its simplicity. Of all the ways to scale dynamically-constrained optimal control problems subject to transcription in their solution procedures, IS is on the lower end of the spectrum regarding the number of required computations. Another benefit is that very little information is required to perform the relevant computations. Particularly, IS only needs upper and lower bounds on the discretized variables. Therefore, IS requires no prior solution attempts, making it a good "first resort" for trying to autoscale an ill-behaved problem.

However, since IS does not scale non-defect constraints, it is not a method to be used alone, but rather a method to be used in tandem with some other manual or automatic scaling scheme that takes care of such constraints. Also, according to Sagliano, IS fails to take into account the jacobian information describing the dynamic relationships between states/controls and their defects, not to mention the character of the transcription method itself. This negligence, of course, may result in an inadvertently ill-conditioned jacobian---or, at least, one that is not conditioned nearly as well as it could be.


\addcontentsline{toc}{subsection}{Projected Jacobian Rows Normalization}
\subsection*{Projected Jacobian Rows Normalization}

\subsubsection*{Formulation}

The aforementioned drawbacks to isoscaling (IS) are significantly ameliorated by the design of a more complex autoscaling method called \textbf{projected jacobian rows normalization} (PJRN). Introduced by Sagliano et al (2017), PJRN scales not only discretized states/controls $\textbf{V}$ and their associated defects $\textbf{F}$, but also the path constraints $\textbf{G}$, according to
\begin{align*}
    \Hat{\textbf{V}} &= \text{K}_\textbf{V} \textbf{V} + \text{b} \\
    \Hat{\textbf{F}} &= \text{K}_\textbf{F} \textbf{F} \\
    \Hat{\textbf{G}} &= \text{K}_\textbf{G} \textbf{G}
\end{align*}
where $\text{K}_\textbf{V},\text{b}$ are the same as $\text{K},\text{b}$, respectively, in IS, and $\text{K}_\textbf{F},\text{K}_\textbf{G}$ are diagonal matrices whose diagonal elements are given by
\begin{align*}
    \text{ent}_{i,i} \text{K}_\textbf{F} &= \frac{1}{|\nabla \textbf{F} \cdot \text{K}_\textbf{V}^{-1}|_i} \\
    \text{ent}_{i,i} \text{K}_\textbf{G} &= \frac{1}{|\nabla \textbf{G} \cdot \text{K}_\textbf{V}^{-1}|_i}
\end{align*}
where $|*|_i$ denotes the (euclidean) norm of the $i$th row of $*$, and $\nabla \textbf{F}$,$\nabla \textbf{G}$ are taken with respect to $\textbf{V}$ and are thus subjacobians of a total jacobian. (Which total jacobian, exactly? More on that in the Properties section.) \\

\noindent
To be perfectly explicit, the objects $\textbf{V},\Hat{\textbf{V}},\textbf{V}^U,\textbf{V}^L,\textbf{F},\Hat{\textbf{F}},\textbf{G},\Hat{\textbf{G}},\nabla \textbf{F},\nabla \textbf{G},\text{K}_\textbf{V},\text{K}_\textbf{F},\text{K}_\textbf{G},\text{b}$ have the following dimensions:
\begin{align*}
    \text{dim} \textbf{V} = \text{dim} \Hat{\textbf{V}} = \text{dim} \textbf{V}^U = \text{dim} \textbf{V}^L = \text{dim}\,\text{b} &= N \times 1 \\
    \text{dim} \textbf{F} = \text{dim} \Hat{\textbf{F}} &= n_sn \times 1 \\
    \text{dim} \textbf{G} = \text{dim} \Hat{\textbf{G}} &= n_gn \times 1 \\
    \text{dim} \text{K}_\textbf{V} &= N \times N \\
    \text{dim} \text{K}_\textbf{F} &= n_sn \times n_sn \\
    \text{dim} \text{K}_\textbf{G} &= n_gn \times n_gn \\
    \text{dim} \nabla \textbf{F} &= n_sn \times N \\
    \text{dim} \nabla \textbf{G} &= n_gn \times N
\end{align*}
where $N$ is the number of state variables in the \textit{discrete} NLP problem resulting from transcription, $n_s$ is the number of state variables in the \textit{continuous} optimal control problem, $n_g$ is the number of path constraints in the optimal control problem, and $n$ is the number of discretization nodes utilized in the transcription.

\subsubsection*{Implementation}

Let $\texttt{Jac}$ be a valid total jacobian matrix for the problem---e.g., one returned by calling $\texttt{compute\_totals()}$ on the problem's representative $\texttt{Problem}$ instance. $\texttt{Jac}$ is essentially a dictionary mapping a pair of keys to a rectangular array of numbers. The individual elements of these arrays that are \textit{pertinent to the computation of} $\nabla \textbf{F}$ are accessed by the following general scheme:
\begin{align*}
    \texttt{Jac[fname,vname][fnode][vnode]}
\end{align*}
where \texttt{fname} is the global name of a defect, \texttt{vname} is the global name of a state/control variable, and \texttt{fnode}, \texttt{vnode} are non-negative integers referencing the particular discretization nodes at which the defect and variable, respectively, are evaluated. Similarly, elements \textit{pertinent to the computation of} $\nabla \textbf{G}$ are given by
\begin{align*}
    \texttt{Jac[gname,vname][gnode][vnode]}
\end{align*}
where $\texttt{gname}$ and $\texttt{vname}$ are defined analogously.

\subsubsection*{Properties, pros and cons}
[TODO]

\subsubsection*{Modifications}
[TODO]


\newpage
\addcontentsline{toc}{section}{References, Resources, External Links}
\section*{References, Resources, External Links}

\newpage
\addcontentsline{toc}{section}{Equations Cheatsheet}
\section*{Equations Cheatsheet}

\newpage
\addcontentsline{toc}{section}{FAQ}
\section*{FAQ}

\end{document}
